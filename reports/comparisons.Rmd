---
title: "Comparisons"
author: "Carlos Dobler"
date: "2022-10-27"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, out.width = "90%")

source(here::here("scripts/00_setup.R"))


# Load data
dir_results <- "/mnt/bucket_mine/results/global_remo_bootstrap"

dir_results %>% 
  list.files(full.names = T) %>%
  str_subset("2p0C") %>%
  str_subset("SAM", negate = T) -> ff 
  
ff %>% 
  str_split("/", simplify = T) %>% 
  .[,6] %>% 
  str_replace_all("-", "_") %>% 
  str_remove_all(".nc") %>% 
  str_remove_all("days_above_32C_stats_") -> ff_names

ff %>% 
  set_names(ff_names) %>% 
  map(read_ncdf) -> l_s


fn_diff_plot <- function(m){
  
  m %>% 
    as_tibble() %>% 
    pivot_longer(-c(lon, lat), names_to = "stat", values_to = "val") %>% 
    
    ggplot(aes(lon, lat, fill = val)) +
    geom_raster() +
    facet_wrap(~stat, ncol = 2) +
    colorspace::scale_fill_binned_diverging(palette = "Green-Brown",
                                            na.value = "transparent",
                                            n.breaks = 11,
                                            name = "days",
                                            guide = guide_coloursteps(barheight = 14,
                                                                      barwidth = 0.5)) +
    coord_equal() +
    theme(axis.title = element_blank())
}



```

## EUROPE

Here I compare different ensembles of REMO/RegCM model output corresponding to days above 32 C in a 2C warming level.

The following three set of maps compare "raw" output between REMO (3 members), RegCM (3 members), and REMO+RegCM (6 members) ensembles. I show differences in the mean count of days above threshold, as well as percentiles 5th, 50th (median) and 95th.

```{r}

l_s$reg_remo_2p0C - l_s$reg_all_2p0C -> s_diff

fn_diff_plot(s_diff) + 
  labs(title = "Fig. 1. Difference between [REMO] and [REMO+RegCM] ensembles")


```


```{r}

l_s$reg_regcm_2p0C - l_s$reg_all_2p0C -> s_diff

fn_diff_plot(s_diff) +
  labs(title = "Fig. 2. Difference between [RegCM] and [REMO+RegCM] ensembles")


```


```{r}

l_s$reg_regcm_2p0C - l_s$reg_remo_2p0C -> s_diff

fn_diff_plot(s_diff) +
  labs(title = "Fig. 3. Difference between [RegCM] and [REMO] ensembles")

```

The maps above indicate that RegCM and REMO contribute in different ways to the full ensemble. Their different contribution is most evident in Figure 3. Overall, RegCM tends to run "cooler" (less days above threshold) over northern Africa than REMO. 


In the next set of maps I compare some of the previous maps with two bootstrapped experiments conducted with REMO. The first experiment represents a regular bootstrap. For each cell, I resampled the original sample of 63 observations (21 years x 3 REMO models) with replacement 1000 times. This means: imagine I have a bag of 63 balls, each one representing one observation (1 observation = the count of days above 32C in 1 year for 1 model). I randomly pick one ball, register its value, and return it to the bag. I do that 63 times. Then I calculate the mean and percentiles 5th, 50th and 95th out of those 63 observations. Then I re-do that 1000 times. Lastly, I calculate the mean of those 1000 means, 5th, 50th, and 95th percentiles.


```{r}

l_s$reg_remo_2p0C - l_s$bootstd_remo_2p0C -> s_diff

fn_diff_plot(s_diff) +
  labs(title = "Fig. 4. Difference between [REMO] and\n[STD. BOOTSTRAPPED REMO] ensembles")

```


```{r}

l_s$reg_all_2p0C - l_s$bootstd_remo_2p0C -> s_diff

fn_diff_plot(s_diff) +
  labs(title = "Fig. 5. Difference between [REMO+RegCM]\nand [STD. BOOTSTRAPPED REMO] ensembles")

```


As a second experiment I conducted a parametric bootstrapping. For each cell, I fitted a binomial distribution to its 63 values. I'm using binomial because our underlying variable is binomial: days either exceed the threshold (= 1), or they don't (= 0). Once fitted, I generate 1000 samples of 63 observations based on that distribution. And then, same as before, I calculate the mean and percentiles of the 63 observations for each of the 1000 iterations, to then calculate the mean of those 1000 statistics.

Note: when fitting a distribution we assume our data (the 63 observations) is "incomplete"; it's just a sample out of a larger "population". A fitted distribution essentially represents how that population looks like. The following figure shows nine examples comparing the empirical ("observed") distribution of the 63 observations found in a cell (solid line) and their fitted distribution (dashed).

```{r}

here::here("tb_tmp.rds") %>% readRDS() -> tb

tb %>% 
  group_by(lat) %>% 
  nest() %>%
  pmap(function(data, ...){
    
    range(data$n_days) %>% 
      diff() %>% 
      {./8} %>% 
      round() -> ext
  
    lim_min <- min(data$n_days)-ext
    lim_min <- ifelse(lim_min < 0, 0, lim_min) 
    
    # tibble(count_days = seq(lim_min,(max(data$n_days)+ext)),
    #        
    #        fitted = dbinom(count_days, 
    #                        365, 
    #                        mean(data$n_days/365)),
    #        
    #        observed = density(data$n_days, 
    #                           n = length(count_days), 
    #                           from = min(count_days), 
    #                           to = max(count_days))$y) %>%
    #   
    #   ggplot(aes(x = count_days)) +
    #   geom_line(aes(y = fitted), linetype = "2222") +
    #   geom_line(aes(y = observed)) +
    #   theme(axis.title.y = element_blank(),
    #         axis.ticks.y = element_blank(),
    #         axis.text.y = element_blank())
    
    
    ks <- ks.test(jitter(data$n_days), "pbinom", size = 365, prob = mean(data$n_days)/365)$p.value
    
    tibble(count_days = seq(min(data$n_days), max(data$n_days), length.out = 100),
           fitted = pbinom(count_days, 365, mean(data$n_days/365)),
           observed = ecdf(data$n_days)(count_days)) %>% 
    
      ggplot(aes(x = count_days)) +
      geom_line(aes(y = fitted), linetype = "2222") +
      geom_line(aes(y = observed)) +
      labs(y = "probability",
           caption = str_glue("KS p-value: {round(ks,3)}"))
    

  }) -> l_plots
  
l_plots %>% 
  .[1:9] %>% 
  patchwork::wrap_plots(ncol = 3)


# tb %>% 
#   filter(round(lat,1) == 33.1) %>% 
#   pull(n_days) -> x
# 
# ks.test(jitter(x), "pbinom", size = 365, prob = mean(x/365))
# ks.test(runif(63, min = min(x), max = max(x)),
#         "pbinom", size = 365, prob = mean(x/365))


# Ho: There is no difference between distributions/ data coms from the specified distribution
# p-value < 0.05: reject null hypothesis (distributions are different)
# p-value > 0.05: accept null hypothesis / no evidence against null hypothesis



```

As mentioned above, from the fitted distribution I drew 1000 random samples of 63 observations and calculated the means of the 1000 means and percentiles. See below how that ensemble compares with the raw REMO ensemble and the full ensemble.


```{r}

l_s$reg_remo_2p0C - select(l_s$bootparam_remo_2p0C, c(2,5,8,11)) -> s_diff

fn_diff_plot(s_diff) +
  labs(title = "Fig. 6. Difference between [REMO] and\n[PARAM. BOOTSTRAPPED REMO] ensembles")

```


```{r}

l_s$reg_all_2p0C - select(l_s$bootparam_remo_2p0C, c(2,5,8,11)) -> s_diff

fn_diff_plot(s_diff) +
  labs(title = "Fig. 7. Difference between [REMO+RegCM]\nand [PARAM. BOOTSTRAPPED REMO] ensembles")

```

The following map compares the two bootstrap experiments:

```{r}

l_s$bootstd_remo_2p0C - select(l_s$bootparam_remo_2p0C, c(2,5,8,11)) -> s_diff

fn_diff_plot(s_diff) +
  labs(title = "Fig. 8. Difference between [STD. BOOTSTRAPPED REMO]\nand [PARAM. BOOTSTRAPPED REMO] ensembles")

```

The bootstrapped ensembles seem to obtain similar mean values to the full ensemble (REMO+RegCM), although they deviate more over the tails (5th and 95th percentiles). Both bootstrapped ensembles run "hotter" in the 5th percentile than the full ensemble (more days above threshold, particularly over northern Africa), and "cooler" in the 95th percentile (particularly over eastern Europe). Between both bootstrapped ensembles, mean values are quite similar, but the standard one is "cooler" than the parametric in the 5th percentile, and "warmer" in the 95th percentile.


Note: the 1000 means (or any of the percentiles) I obtain from bootstrapping are theoretically normally distributed. For example, this is the distribution of the 63 "raw" observations of one cell:

```{r, fig.height=3}

tb %>%
  filter(round(lat,1) == 29.5) %>% 
  ggplot(aes(n_days)) +
  geom_histogram(bins = 20, fill = "grey80", color = "grey20")

```

And below are the distributions of the 1000 means, 5th, and 95th percentiles that came from bootstrapping those 63 "raw" observations. The fact that they are normally distributed means I can calculate their 2.5th and 97.5th percentiles to obtain my 95% confidence interval (red dashed lines). With those numbers I can state something like, "based on REMO, the mean count of days above 32C is between 174 and 178 with 95% confidence" (based on the left facet).

```{r, fig.height=2}



tb %>%
  filter(round(lat,1) == 29.5) %>%
  pull(n_days) -> x

map_dfr(seq_len(1000), function(...){
  
  rbinom(63, 365, mean(x/365)) %>% 
    {c(mean(.), quantile(., c(0.05, 0.50, 0.95)))} %>% 
    set_names(c("mean", "p05", "p50", "p95"))
  
  # sample(x, length(x), replace = T) %>%
  #   jitter() %>% 
  #   {c(mean(.), quantile(., c(0.05, 0.50, 0.95)))} %>% 
  #   set_names(c("mean", "p05", "p50", "p95"))
  
}) -> tb_resamples

c("mean", "p05", "p95") %>% 
  map(function(col_){
    
    tb_resamples %>% 
      select(col_) %>% 
      rename_with(~"var") -> tb_col
    
    tb_col %>% 
      pull(var) %>% 
      {c(quantile(., c(0.025, 0.925)))} -> ci
    
    tb_col %>% 
      ggplot(aes(var)) +
      geom_density(bw = 0.7) +
      # geom_histogram(fill = "grey80", color = "grey20", bins = 25) +
      # geom_vline(xintercept = ci[1], color = "red") +
      geom_vline(xintercept = ci[c(1,2)], color = "red", linetype = "3232") +
      labs(title = col_,
           caption = str_glue("95% conf. int.: {round(ci[1])} - {round(ci[2])}")) +
      theme(axis.title.x = element_blank())
    
  }) %>% 
  patchwork::wrap_plots(nrow = 1)


```

## SOUTH AMERICA

Now I'll show same set of comparisons for SAM domain.

```{r}

dir_results %>% 
  list.files(full.names = T) %>%
  str_subset("2p0C") %>%
  str_subset("SAM", negate = F) -> ff 
  
ff %>% 
  str_split("/", simplify = T) %>% 
  .[,6] %>% 
  str_replace_all("-", "_") %>% 
  str_remove_all(".nc") %>% 
  str_remove_all("SAM_days_above_32C_stats_") -> ff_names

ff %>% 
  set_names(ff_names) %>% 
  map(read_ncdf) -> l_s

```


```{r}

l_s$reg_remo_2p0C - l_s$reg_all_2p0C -> s_diff

fn_diff_plot(s_diff) + 
  labs(title = "Fig. 1. Difference between [REMO] and [REMO+RegCM] ensembles")


```


```{r}

l_s$reg_regcm_2p0C - l_s$reg_all_2p0C -> s_diff

fn_diff_plot(s_diff) +
  labs(title = "Fig. 2. Difference between [RegCM] and [REMO+RegCM] ensembles")

```


```{r}

l_s$reg_regcm_2p0C - l_s$reg_remo_2p0C -> s_diff

fn_diff_plot(s_diff) +
  labs(title = "Fig. 3. Difference between [RegCM] and [REMO] ensembles")

```


```{r}

l_s$reg_remo_2p0C - l_s$bootstd_remo_2p0C -> s_diff

fn_diff_plot(s_diff) +
  labs(title = "Fig. 4. Difference between [REMO] and\n[STD. BOOTSTRAPPED REMO] ensembles")

```


```{r}

l_s$reg_all_2p0C - l_s$bootstd_remo_2p0C -> s_diff

fn_diff_plot(s_diff) +
  labs(title = "Fig. 5. Difference between [REMO+RegCM]\nand [STD. BOOTSTRAPPED REMO] ensembles")

```

```{r}

l_s$reg_remo_2p0C - select(l_s$bootparam_remo_2p0C, c(2,5,8,11)) -> s_diff

fn_diff_plot(s_diff) +
  labs(title = "Fig. 6. Difference between [REMO] and\n[PARAM. BOOTSTRAPPED REMO] ensembles")

```

```{r}

l_s$reg_all_2p0C - select(l_s$bootparam_remo_2p0C, c(2,5,8,11)) -> s_diff

fn_diff_plot(s_diff) +
  labs(title = "Fig. 7. Difference between [REMO+RegCM]\nand [PARAM. BOOTSTRAPPED REMO] ensembles")

```

```{r}

l_s$bootstd_remo_2p0C - select(l_s$bootparam_remo_2p0C, c(2,5,8,11)) -> s_diff

fn_diff_plot(s_diff) +
  labs(title = "Fig. 8. Difference between [STD. BOOTSTRAPPED REMO]\nand [PARAM. BOOTSTRAPPED REMO] ensembles")

```


